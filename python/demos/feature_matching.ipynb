{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316a3adc-c895-4b07-8bab-f5585005d2d3",
   "metadata": {},
   "source": [
    "# 特徴点マッチングによる物体検出\n",
    "\n",
    "Opencvのインストールを行うコマンドが入っています。一度実行した後はこの処理はスキップ可能です。初回インストール後にkernelの再起動が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5363a-dac6-4845-b3d4-8040d1b6b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65788083-50ff-4331-b8e7-ed9f419775cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup_demo_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42b6b2-b4dd-491e-9e7b-e499bc2eaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import grpc\n",
    "import kachaka_api_pb2\n",
    "import numpy as np\n",
    "from IPython.display import Image, clear_output, display\n",
    "from kachaka_api_pb2_grpc import KachakaApiStub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196a83a-d14e-4a7b-8bf9-dbfc5c4643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stub = KachakaApiStub(grpc.aio.insecure_channel(kachaka_api_server))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d88c44-428b-4c61-8338-36581994d9c4",
   "metadata": {},
   "source": [
    "以下を実行したら、認識させたい物体をカメラ画像の赤枠内に表示させて下さい。10秒経つと撮影されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc841281-86d1-439d-a5d0-b46e618211b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = kachaka_api_pb2.GetRequest()\n",
    "\n",
    "target_area_length = 400\n",
    "time_to_capture = 10\n",
    "\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    resp = await stub.GetFrontCameraRosCompressedImage(req)\n",
    "    req.metadata.cursor = resp.metadata.cursor\n",
    "    image = cv2.imdecode(np.frombuffer(resp.image.data, dtype=np.uint8), flags=1)\n",
    "    start_x = int(image.shape[1] / 2 - target_area_length / 2)\n",
    "    start_y = int(image.shape[0] / 2 - target_area_length / 2)\n",
    "    end_x = int(image.shape[1] / 2 + target_area_length / 2)\n",
    "    end_y = int(image.shape[0] / 2 + target_area_length / 2)\n",
    "\n",
    "    remaining_time = time_to_capture - (time.time() - start_time)\n",
    "    text = f\"{remaining_time:.2f} [sec]\" if remaining_time > 0 else \"capture!\"\n",
    "\n",
    "    image = cv2.rectangle(\n",
    "        image, (start_x, start_y), (end_x, end_y), (0, 0, 255), thickness=2\n",
    "    )\n",
    "    image = cv2.putText(\n",
    "        image,\n",
    "        text,\n",
    "        (start_x, start_y - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    _, ret = cv2.imencode(\n",
    "        \".jpg\", cv2.resize(image, (int(image.shape[1] / 2), int(image.shape[0] / 2)))\n",
    "    )\n",
    "    clear_output(wait=True)\n",
    "    display(Image(data=ret, format=\"jpeg\"))\n",
    "    if remaining_time <= 0.0:\n",
    "        break\n",
    "    req.metadata.cursor = resp.metadata.cursor\n",
    "\n",
    "orig_image = cv2.imdecode(np.frombuffer(resp.image.data, dtype=np.uint8), flags=1)[\n",
    "    start_y:end_y, start_x:end_x\n",
    "]\n",
    "orb = cv2.ORB_create()\n",
    "orig_keypoints, orig_descriptors = orb.detectAndCompute(orig_image, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8df200-b3b8-405f-945c-4b40f1af5dc3",
   "metadata": {},
   "source": [
    "撮影した物体をカメラに映してみて下さい。特徴点マッチングが行われている様子を確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac442c-688a-4569-9d1b-2ab246b3c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "ratio_threshold = 0.75\n",
    "\n",
    "while True:\n",
    "    resp = await stub.GetFrontCameraRosCompressedImage(req)\n",
    "    image = cv2.imdecode(np.frombuffer(resp.image.data, dtype=np.uint8), flags=1)\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    matches = bf.knnMatch(orig_descriptors, descriptors, k=2)\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_threshold * n.distance:\n",
    "            good.append([m])\n",
    "    image = cv2.drawMatchesKnn(\n",
    "        orig_image,\n",
    "        orig_keypoints,\n",
    "        image,\n",
    "        keypoints,\n",
    "        good,\n",
    "        None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    "    )\n",
    "    image = cv2.putText(\n",
    "        image,\n",
    "        f\"good matches: {len(good)}\",\n",
    "        (50, image.shape[0] - 150),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    clear_output(wait=True)\n",
    "    _, ret = cv2.imencode(\n",
    "        \".jpg\", cv2.resize(image, (int(image.shape[1] / 2), int(image.shape[0] / 2)))\n",
    "    )\n",
    "    display(Image(data=ret, format=\"jpeg\"))\n",
    "    req.metadata.cursor = resp.metadata.cursor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
